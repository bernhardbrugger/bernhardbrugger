{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Description of the evaluation metric\nThis competition is evaluated on the mean **Dice coefficient**. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:\n\n2âˆ—|ð‘‹âˆ©ð‘Œ|/|ð‘‹|+|ð‘Œ|\n\nwhere X is the predicted set of pixels and Y is the ground truth. The Dice coefficient is defined to be 1 when both X and Y are empty. The leaderboard score is the mean of the Dice coefficients for each image in the test set.\n\nSubmission File\nIn order to reduce the submission file size, our metric uses run-length encoding on the pixel values. Instead of submitting an exhaustive list of indices for your segmentation, you will submit pairs of values that contain a start position and a run length. E.g. '1 3' implies starting at pixel 1 and running a total of 3 pixels (1,2,3).\n\nNote that, at the time of encoding, the mask should be binary, meaning the masks for all objects in an image are joined into a single large mask. A value of 0 should indicate pixels that are not masked, and a value of 1 will indicate pixels that are masked.\n\nThe competition format requires a space delimited list of pairs. For example, '1 3 10 5' implies pixels 1,2,3,10,11,12,13,14 are to be included in the mask. The metric checks that the pairs are sorted, positive, and the decoded pixel values are not duplicated. The pixels are numbered from top to bottom, then left to right: 1 is pixel (1,1), 2 is pixel (2,1), etc.\n\n# Files\n* [train/test].csv Metadata for the train/test set. Only the first few rows of the test set are available for download.\n\n* id - The image ID.\n* organ - The organ that the biopsy sample was taken from.\n* data_source - Whether the image was provided by HuBMAP or HPA.\n* img_height - The height of the image in pixels.\n* img_width - The width of the image in pixels.\n* pixel_size - The height/width of a single pixel from this image in micrometers. All HPA images have a pixel size of 0.4 Âµm. For HuBMAP imagery the pixel size is 0.5 Âµm for kidney, 0.2290 Âµm for large intestine, 0.7562 Âµm for lung, 0.4945 Âµm for spleen, and 6.263 Âµm for prostate.\n* tissue_thickness - The thickness of the biopsy sample in micrometers. All HPA images have a thickness of 4 Âµm. The HuBMAP samples have tissue slice thicknesses 10 Âµm for kidney, 8 Âµm for large intestine, 4 Âµm for spleen, 5 Âµm for lung, and 5 Âµm for prostate.\n* rle - The target column. A run length encoded copy of the annotations. Provided for the training set only.\n* age - The patient's age in years. Provided for the training set only.\n* sex - The sex of the patient. Provided for the training set only.\n* sample_submission.csv\n\n* id - The image ID.\n* rle - A run length encoded mask of the FTUs in the image.\n* [train/test]_images/ The images. Expect roughly 550 images in the hidden test set. All HPA images are 3000 x 3000 pixels with a tissue area within the image around 2500 x 2500 pixels. The HuBMAP images range in size from 4500x4500 down to 160x160 pixels. HPA samples were stained with antibodies visualized with 3,3'-diaminobenzidine (DAB) and counterstained with hematoxylin. HuBMAP images were prepared using Periodic acid-Schiff (PAS)/hematoxylin and eosin (H&E) stains. All images used have at least one FTU. All tissue data used in this competition is from healthy donors that pathologists identified as pathologically unremarkable tissue.\n\n* train_annotations/ The annotations provided in the format of points that define the boundaries of the polygon masks of the FTUs.","metadata":{}},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nimport cv2\nimport tifffile\nfrom fastai.vision.all import *\nfrom fastai.callback.hook import *\nfrom fastai.data.all import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-22T13:03:07.996376Z","iopub.execute_input":"2022-09-22T13:03:07.996848Z","iopub.status.idle":"2022-09-22T13:03:12.746308Z","shell.execute_reply.started":"2022-09-22T13:03:07.996753Z","shell.execute_reply":"2022-09-22T13:03:12.744644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make dir\n!mkdir -p /root/.cache/torch/hub/checkpoints\n\n\n#Resnet34\n!cp ../input/resnet34/resnet34-b627a593.pth /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n#Resnet50\n!cp ../input/resnet50/resnet50-0676ba61.pth /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n#Resnet101\n!cp ../input/resnet101/resnet101-63fe2227.pth /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:12.807974Z","iopub.execute_input":"2022-09-22T13:03:12.809675Z","iopub.status.idle":"2022-09-22T13:03:27.668951Z","shell.execute_reply.started":"2022-09-22T13:03:12.809605Z","shell.execute_reply":"2022-09-22T13:03:27.667371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Paths\n_BASE_DIR = '../input/hubmap-2022-512x512'\n_IMG_DIR = os.path.join(_BASE_DIR,'train')\n_MSK_DIR = os.path.join(_BASE_DIR,'masks')\n\n# Data\ntraindf = pd.read_csv('/kaggle/input/hubmap-organ-segmentation/train.csv')\nN_SAMPLES = len(traindf)\nN_ORGANS = traindf['organ'].nunique()\nORGANS = sorted(traindf['organ'].unique())\nORGAN_CATS = {ORGANS[0]: 1, ORGANS[1]: 2, ORGANS[2]: 3, ORGANS[3]: 4, ORGANS[4]: 5}\n\n# Params\nBATCH_SIZE = 2\nIMAGE_SIZE = 512\nIMAGE_RESIZE = IMAGE_SIZE // 2\nTHRESHOLD = .39\nM_DIR = './model'\nOPTIMIZER = ranger\nACTIVATION_F = Mish\nTEST_IMG_SIZE = 512","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:27.672562Z","iopub.execute_input":"2022-09-22T13:03:27.672974Z","iopub.status.idle":"2022-09-22T13:03:28.094744Z","shell.execute_reply.started":"2022-09-22T13:03:27.672936Z","shell.execute_reply":"2022-09-22T13:03:28.092426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print data infos\nprint('-'*50)\nprint(f'''\n[Info] Organ information:     \n\n        N_SAMPLES: {N_SAMPLES}\n        N_ORGANS: {N_ORGANS}\n        ORGAN NAMES: {ORGANS}\n        ORGAN CATEGORIES: {ORGAN_CATS}\n\n''')\nprint('-'*50)\n\ndisplay(traindf.info())\ndisplay(traindf.describe())","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:28.096341Z","iopub.execute_input":"2022-09-22T13:03:28.096775Z","iopub.status.idle":"2022-09-22T13:03:28.265899Z","shell.execute_reply.started":"2022-09-22T13:03:28.096739Z","shell.execute_reply":"2022-09-22T13:03:28.263114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Func for train images and masks\ndef get_img_fn(path): return get_image_files(path)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:28.268302Z","iopub.execute_input":"2022-09-22T13:03:28.268653Z","iopub.status.idle":"2022-09-22T13:03:28.274702Z","shell.execute_reply.started":"2022-09-22T13:03:28.268623Z","shell.execute_reply":"2022-09-22T13:03:28.273132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test func on images\nimg_fnames = get_img_fn(_IMG_DIR)\nimg_fnames[:3]","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:28.276882Z","iopub.execute_input":"2022-09-22T13:03:28.277525Z","iopub.status.idle":"2022-09-22T13:03:31.048648Z","shell.execute_reply.started":"2022-09-22T13:03:28.277461Z","shell.execute_reply":"2022-09-22T13:03:31.047056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test func on masks\nlabel_fnames = get_image_files(_MSK_DIR)\nlabel_fnames[:3]","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:31.050633Z","iopub.execute_input":"2022-09-22T13:03:31.051079Z","iopub.status.idle":"2022-09-22T13:03:33.663805Z","shell.execute_reply.started":"2022-09-22T13:03:31.051042Z","shell.execute_reply":"2022-09-22T13:03:33.662547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot test image\nimg_f = img_fnames[12]\nimg = load_image(img_f)\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:33.665206Z","iopub.execute_input":"2022-09-22T13:03:33.666646Z","iopub.status.idle":"2022-09-22T13:03:34.075275Z","shell.execute_reply.started":"2022-09-22T13:03:33.666605Z","shell.execute_reply":"2022-09-22T13:03:34.074324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Func for defining label path for data block\nget_msk_fn = lambda x: f'{_MSK_DIR}/{x.stem}{x.suffix}'","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:34.078859Z","iopub.execute_input":"2022-09-22T13:03:34.079592Z","iopub.status.idle":"2022-09-22T13:03:34.086043Z","shell.execute_reply.started":"2022-09-22T13:03:34.079532Z","shell.execute_reply":"2022-09-22T13:03:34.084714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test func\nget_msk_fn(img_f)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:34.087454Z","iopub.execute_input":"2022-09-22T13:03:34.088186Z","iopub.status.idle":"2022-09-22T13:03:34.100889Z","shell.execute_reply.started":"2022-09-22T13:03:34.088149Z","shell.execute_reply":"2022-09-22T13:03:34.099915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot test mask\nmsk = Image.open(get_msk_fn(img_f))\nplt.imshow(msk)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:34.102433Z","iopub.execute_input":"2022-09-22T13:03:34.102829Z","iopub.status.idle":"2022-09-22T13:03:34.325744Z","shell.execute_reply.started":"2022-09-22T13:03:34.102794Z","shell.execute_reply":"2022-09-22T13:03:34.324509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define blocks\nblocks = (ImageBlock, MaskBlock(ORGANS))","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:34.327532Z","iopub.execute_input":"2022-09-22T13:03:34.328134Z","iopub.status.idle":"2022-09-22T13:03:34.334717Z","shell.execute_reply.started":"2022-09-22T13:03:34.328081Z","shell.execute_reply":"2022-09-22T13:03:34.333554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build data block\ndblock = DataBlock(blocks    = blocks,\n                   get_items = get_img_fn,\n                   get_y     = get_msk_fn,\n                   splitter  = RandomSplitter(),\n                   item_tfms = Resize(IMAGE_RESIZE))","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:34.336636Z","iopub.execute_input":"2022-09-22T13:03:34.337112Z","iopub.status.idle":"2022-09-22T13:03:34.348764Z","shell.execute_reply.started":"2022-09-22T13:03:34.337069Z","shell.execute_reply":"2022-09-22T13:03:34.347348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print summary of data block\ndblock.summary(_IMG_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:34.352112Z","iopub.execute_input":"2022-09-22T13:03:34.352623Z","iopub.status.idle":"2022-09-22T13:03:35.275777Z","shell.execute_reply.started":"2022-09-22T13:03:34.352563Z","shell.execute_reply":"2022-09-22T13:03:35.274495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define data loader\ndls = dblock.dataloaders(_IMG_DIR, \n                         bs=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:35.279440Z","iopub.execute_input":"2022-09-22T13:03:35.280295Z","iopub.status.idle":"2022-09-22T13:03:35.403048Z","shell.execute_reply.started":"2022-09-22T13:03:35.280252Z","shell.execute_reply":"2022-09-22T13:03:35.402097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot batch of 4\ndls.train.show_batch(max_n=4, nrows=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:35.404418Z","iopub.execute_input":"2022-09-22T13:03:35.405062Z","iopub.status.idle":"2022-09-22T13:03:35.776972Z","shell.execute_reply.started":"2022-09-22T13:03:35.405007Z","shell.execute_reply":"2022-09-22T13:03:35.775623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check sizes of tensors\nb = dls.one_batch()\nlen(b), b[0].shape, b[1].shape","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:35.778365Z","iopub.execute_input":"2022-09-22T13:03:35.778706Z","iopub.status.idle":"2022-09-22T13:03:35.905343Z","shell.execute_reply.started":"2022-09-22T13:03:35.778675Z","shell.execute_reply":"2022-09-22T13:03:35.904124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define training model --- Used model: UNET with Resnet backbone\nlearn = unet_learner(dls, \n                     resnet101,  \n                     model_dir=M_DIR, \n                     self_attention=True, \n                     act_cls=ACTIVATION_F, \n                     opt_func=OPTIMIZER\n                    )\nlearn.path = Path(M_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:35.906999Z","iopub.execute_input":"2022-09-22T13:03:35.907762Z","iopub.status.idle":"2022-09-22T13:03:57.218006Z","shell.execute_reply.started":"2022-09-22T13:03:35.907696Z","shell.execute_reply":"2022-09-22T13:03:57.214526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use fastai method for finding learning rate\nlearn.lr_find(suggest_funcs=(minimum, steep, valley, slide))","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.219603Z","iopub.status.idle":"2022-09-22T13:03:57.220242Z","shell.execute_reply.started":"2022-09-22T13:03:57.219911Z","shell.execute_reply":"2022-09-22T13:03:57.219938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit method: Fit one cycle\nlearn.fit_one_cycle(1, slice(1e-06,1e-03), pct_start=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.222090Z","iopub.status.idle":"2022-09-22T13:03:57.223366Z","shell.execute_reply.started":"2022-09-22T13:03:57.223035Z","shell.execute_reply":"2022-09-22T13:03:57.223068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot sample results\nlearn.show_results()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.225263Z","iopub.status.idle":"2022-09-22T13:03:57.225861Z","shell.execute_reply.started":"2022-09-22T13:03:57.225555Z","shell.execute_reply":"2022-09-22T13:03:57.225593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unfreeze weigths for second training round\nlearn.unfreeze()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.227673Z","iopub.status.idle":"2022-09-22T13:03:57.228831Z","shell.execute_reply.started":"2022-09-22T13:03:57.228502Z","shell.execute_reply":"2022-09-22T13:03:57.228534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use fastai method for finding learning rate 2\nlearn.lr_find()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.230325Z","iopub.status.idle":"2022-09-22T13:03:57.231488Z","shell.execute_reply.started":"2022-09-22T13:03:57.231182Z","shell.execute_reply":"2022-09-22T13:03:57.231213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit method: Fit one cycle 2\nlearn.fit_one_cycle(2, slice(1e-5,1e-4), pct_start=0.8)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.233226Z","iopub.status.idle":"2022-09-22T13:03:57.233822Z","shell.execute_reply.started":"2022-09-22T13:03:57.233516Z","shell.execute_reply":"2022-09-22T13:03:57.233544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot sample results 2\nlearn.show_results()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.235873Z","iopub.status.idle":"2022-09-22T13:03:57.236847Z","shell.execute_reply.started":"2022-09-22T13:03:57.236511Z","shell.execute_reply":"2022-09-22T13:03:57.236542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test image\ndef get_img(img_path): return tifffile.imread(img_path)\n\ntest_img = get_img('../input/hubmap-organ-segmentation/test_images/10078.tiff')","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.238200Z","iopub.status.idle":"2022-09-22T13:03:57.239249Z","shell.execute_reply.started":"2022-09-22T13:03:57.238912Z","shell.execute_reply":"2022-09-22T13:03:57.238944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pred mask\ntest_pred = learn.predict(test_img)\nmask_pred = list(zip(*test_pred))[0][2]","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.241144Z","iopub.status.idle":"2022-09-22T13:03:57.241729Z","shell.execute_reply.started":"2022-09-22T13:03:57.241431Z","shell.execute_reply":"2022-09-22T13:03:57.241458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test dataframe for information purposes\ntestdf = pd.read_csv('../input/hubmap-organ-segmentation/test.csv')\ntestdf","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.243652Z","iopub.status.idle":"2022-09-22T13:03:57.244263Z","shell.execute_reply.started":"2022-09-22T13:03:57.243937Z","shell.execute_reply":"2022-09-22T13:03:57.243965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resize tensor to original shape and make predicted mask area more visible by thresold\ndef resize_tensor(tensor, size=None, dtype=np.uint8): return cv2.resize(tensor, [size, size], interpolation=cv2.INTER_CUBIC).astype(dtype)\n\nmask_pred_resized = resize_tensor(mask_pred.numpy(), size=TEST_IMG_SIZE, dtype=np.float32)\nmask_binary = (mask_pred_resized > THRESHOLD).astype(np.int8)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.246294Z","iopub.status.idle":"2022-09-22T13:03:57.247324Z","shell.execute_reply.started":"2022-09-22T13:03:57.246966Z","shell.execute_reply":"2022-09-22T13:03:57.246999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot original test image and predicted binary mask\nf, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n# --------------------------------------------------------------\nax[0].imshow(test_img)\nax[0].set_title(f'Original', size=16)\n\nax[1].imshow(mask_binary)\nax[1].set_title(f'Pred_Mask', size=16)\n# --------------------------------------------------------------\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.249489Z","iopub.status.idle":"2022-09-22T13:03:57.250574Z","shell.execute_reply.started":"2022-09-22T13:03:57.250156Z","shell.execute_reply":"2022-09-22T13:03:57.250207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Func for converting binary mask image to run length encoding (rle), which is the target variable in this competition\ndef mask2rle(mask, orig_dim=TEST_IMG_SIZE):\n    #Rescale image to original size\n    size = int(len(mask.flatten())**.5)\n    n = Image.fromarray(mask.reshape((size, size))*255.0)\n    n = n.resize((orig_dim, orig_dim))\n    n = np.array(n).astype(np.float32)\n    #Get pixels to flatten\n    pixels = n.T.flatten()\n    #Round the pixels using the half of the range of pixel value\n    pixels = (pixels-min(pixels) > ((max(pixels)-min(pixels))/2)).astype(int)\n    pixels = np.nan_to_num(pixels) #incase of zero-div-error\n    \n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0]\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.252638Z","iopub.status.idle":"2022-09-22T13:03:57.253967Z","shell.execute_reply.started":"2022-09-22T13:03:57.253617Z","shell.execute_reply":"2022-09-22T13:03:57.253653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting binary mask\nrle = mask2rle(mask_binary)\nrle","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.255396Z","iopub.status.idle":"2022-09-22T13:03:57.255989Z","shell.execute_reply.started":"2022-09-22T13:03:57.255690Z","shell.execute_reply":"2022-09-22T13:03:57.255719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate over test images (in this case only one) and build submission dataframe\nimport gc\ndf_sample = pd.read_csv('../input/hubmap-organ-segmentation/sample_submission.csv')\nTEST_IMG_DIR = '../input/hubmap-organ-segmentation/test_images/'\n\nnames,preds = [],[]\nfor idx,row in df_sample.iterrows():\n    idx = str(row['id'])\n    ds = get_img(os.path.join(TEST_IMG_DIR,idx+'.tiff'))\n    mp = learn.predict(ds)\n    mp = list(zip(*mp))[0][2]\n    mp_resized = resize_tensor(mp.numpy(), size=2023, dtype=np.float32)\n    mp_binary = (mp_resized > THRESHOLD).astype(np.int8)\n    rle = mask2rle(mp_binary)\n    names.append(idx)\n    preds.append(rle)\n    del ds\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.257917Z","iopub.status.idle":"2022-09-22T13:03:57.258563Z","shell.execute_reply.started":"2022-09-22T13:03:57.258246Z","shell.execute_reply":"2022-09-22T13:03:57.258290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make submission dataframe\ndf = pd.DataFrame({'id':names,'rle':preds})\ndf.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.260569Z","iopub.status.idle":"2022-09-22T13:03:57.261389Z","shell.execute_reply.started":"2022-09-22T13:03:57.260987Z","shell.execute_reply":"2022-09-22T13:03:57.261019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Final check\ndf","metadata":{"execution":{"iopub.status.busy":"2022-09-22T13:03:57.263603Z","iopub.status.idle":"2022-09-22T13:03:57.264285Z","shell.execute_reply.started":"2022-09-22T13:03:57.263940Z","shell.execute_reply":"2022-09-22T13:03:57.263968Z"},"trusted":true},"execution_count":null,"outputs":[]}]}