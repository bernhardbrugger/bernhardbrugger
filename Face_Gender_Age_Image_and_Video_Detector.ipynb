{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bernhardbrugger/bernhardbrugger/blob/main/Face_Gender_Age_Image_and_Video_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This is a short script that enables face detection and gender + age prediction using computer vision. "
      ],
      "metadata": {
        "id": "YOlIXcbWKDfk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJZmMnamHjUn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmArG-UcHjUy"
      },
      "outputs": [],
      "source": [
        "# define the groups of ages which should be summarized in order to increase accuracy\n",
        "\n",
        "AGE_GROUPS = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
        "\n",
        "\n",
        "# define the groups of genders which should be summarized in order to increase accuracy\n",
        "\n",
        "GENDER_GROUPS = [\"male\", \"female\"]\n",
        "\n",
        "\n",
        "# load the pretrained face detector model\n",
        "\n",
        "PBTXT_PATH = r\"..\\opencv_face_detector.pbtxt\"\n",
        "\n",
        "PB_PATH = r\"..\\opencv_face_detector_uint8.pb\"\n",
        "\n",
        "face_architecture = cv2.dnn.readNet(PBTXT_PATH, PB_PATH)\n",
        "\n",
        "\n",
        "# load the pretrained gender detector model\n",
        "\n",
        "PBTXT_PATH = r\"..\\gender_deploy.prototxt\"\n",
        "\n",
        "CAF_PATH = r\"..\\gender_net.caffemodel\"\n",
        "\n",
        "gender_architecture = cv2.dnn.readNet(PBTXT_PATH, CAF_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code captures the webcam of your laptop, detects your face and predicts your gender and age\n",
        "\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "while(True):\n",
        "    \n",
        "    ret_val, frame = video_capture.read()\n",
        "    \n",
        "    frame = cv2.resize(frame, (600,400))\n",
        "    \n",
        "    (h, w) = frame.shape[:2]\n",
        "    \n",
        "    blob = cv2.dnn.blobFromImage(frame, 1.0, (227, 227), (104.0, 177.0, 123.0))\n",
        "    \n",
        "    \n",
        "    face_architecture.setInput(blob)\n",
        "    \n",
        "    detections = face_architecture.forward()\n",
        "\n",
        "    \n",
        "    for i in range(0, detections.shape[2]):\n",
        "    \n",
        "        # get probabilities from the prediction\n",
        "    \n",
        "        confidence = detections[0, 0, i, 2]\n",
        "\n",
        "    \n",
        "        # filter low confidences\n",
        "    \n",
        "        # 0.5 is the minimum confidence\n",
        "    \n",
        "        if confidence > 0.5:\n",
        "\n",
        "\n",
        "            # get the coordinates for the bounding boxes\n",
        "\n",
        "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\n",
        "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "        \n",
        "\n",
        "\n",
        "            '''# ensure the face ROI is sufficiently large\n",
        "\n",
        "            if face.shape[0] < 20 or face.shape[1] < 20:\n",
        "\n",
        "                continue'''\n",
        "\n",
        "\n",
        "            # ROI for faces\n",
        " \n",
        "            face = frame[startY:endY, startX:endX]\n",
        " \n",
        "            blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
        "\n",
        "\n",
        "    # age detector\n",
        " \n",
        "    age_architecture.setInput(blob)\n",
        " \n",
        "    predictions = age_architecture.forward()\n",
        " \n",
        "    i = predictions[0].argmax()\n",
        " \n",
        "    age = AGE_GROUPS[i]\n",
        " \n",
        "    age_confidence = predictions[0][i]\n",
        "\n",
        "\n",
        "    # gender detector\n",
        "\n",
        "    gender_architecture.setInput(blob)\n",
        "\n",
        "    predictions = gender_architecture.forward()\n",
        "\n",
        "    i = predictions[0].argmax()\n",
        "\n",
        "    gender = GENDER_GROUPS[i]\n",
        "\n",
        "    gender_confidence = predictions[0][i]\n",
        "\n",
        "\n",
        "    # show prediction in image\n",
        "\n",
        "    txt = \"gender: {}: {:.2f}%; age{}: {:.2f}%\".format(gender, gender_confidence * 100, age, age_confidence * 100)\n",
        "\n",
        "\n",
        "    # draw bounding box and age\n",
        "\n",
        "    if startY - 10 > 10:\n",
        "\n",
        "        y = startY - 10\n",
        "\n",
        "    else:\n",
        "\n",
        "        y = startY + 10\n",
        "\n",
        "\n",
        "    cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "\n",
        "    cv2.putText(frame, txt, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "\n",
        "            \n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "video_capture.release()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "p_gGn72iIGJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvVkx1pJHjU9"
      },
      "outputs": [],
      "source": [
        "# this code uploads a picture of your choice, detects face, predicts gender an age and returns the picture with the detected face and information about gender and age\n",
        "\n",
        "# load and preprocess an image\n",
        "\n",
        "IMAGE_PATH = r\"..\\mark_zuckerberg.jpg\"\n",
        "\n",
        "img = cv2.imread(IMAGE_PATH)\n",
        "\n",
        "(h, w) = img.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(img, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "\n",
        "\n",
        "# pass the image through the network\n",
        "\n",
        "face_architecture.setInput(blob)\n",
        "\n",
        "detections = face_architecture.forward()\n",
        "\n",
        "\n",
        "# get ROI coordinates\n",
        "\n",
        "for i in range(0, detections.shape[2]):\n",
        "\n",
        "    # get probabilities from the prediction\n",
        "\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "\n",
        "\n",
        "    # filter low confidences\n",
        "\n",
        "    # 0.5 is the minimum confidence\n",
        "\n",
        "    if confidence > 0.5:\n",
        "\n",
        "\n",
        "        # get the coordinates for the bounding boxes\n",
        "\n",
        "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\n",
        "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\n",
        "        # ROI for faces\n",
        "\n",
        "        face = img[startY:endY, startX:endX]\n",
        "\n",
        "        blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), (78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
        "\n",
        "\n",
        "# age detector\n",
        "\n",
        "age_architecture.setInput(blob)\n",
        "\n",
        "predictions = age_architecture.forward()\n",
        "\n",
        "i = predictions[0].argmax()\n",
        "\n",
        "age = AGE_GROUPS[i]\n",
        "\n",
        "age_confidence = predictions[0][i]\n",
        "\n",
        "\n",
        "# gender detector\n",
        "\n",
        "gender_architecture.setInput(blob)\n",
        "\n",
        "predictions = gender_architecture.forward()\n",
        "\n",
        "i = predictions[0].argmax()\n",
        "\n",
        "gender = GENDER_GROUPS[i]\n",
        "\n",
        "gender_confidence = predictions[0][i]\n",
        "\n",
        "\n",
        "# show prediction in image\n",
        "\n",
        "txt = \"gender: {}: {:.2f}%; age{}: {:.2f}%\".format(gender, gender_confidence * 100, age, age_confidence * 100)\n",
        "\n",
        "\n",
        "# draw bounding box and age\n",
        "\n",
        "if startY - 10 > 10:\n",
        "\n",
        "    y = startY - 10\n",
        "\n",
        "else:\n",
        "\n",
        "    y = startY + 10\n",
        "\n",
        "\n",
        "cv2.rectangle(img, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
        "\n",
        "cv2.putText(img, txt, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "# display output\n",
        "\n",
        "cv2.imshow(\"Image\", img)\n",
        "\n",
        "cv2.waitKey(0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Face Gender Age Image and Video Detector.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}