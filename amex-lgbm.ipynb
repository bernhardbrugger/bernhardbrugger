{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport os\nimport dill as pickle\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-19T10:16:07.815346Z","iopub.execute_input":"2022-08-19T10:16:07.816256Z","iopub.status.idle":"2022-08-19T10:16:12.130852Z","shell.execute_reply.started":"2022-08-19T10:16:07.816152Z","shell.execute_reply":"2022-08-19T10:16:12.129490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def learning_rate_02_decay_power_099(current_iter):\n    base_learning_rate = .2\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-4 else 1e-4","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:16:12.136985Z","iopub.execute_input":"2022-08-19T10:16:12.139603Z","iopub.status.idle":"2022-08-19T10:16:12.148136Z","shell.execute_reply.started":"2022-08-19T10:16:12.139565Z","shell.execute_reply":"2022-08-19T10:16:12.146830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    _TRAIN = True\n    input_dir_default = '../input/amex-default-prediction'\n    input_dir_parquet = '../input/amex-denoised-aggregated-features'\n    input_dir_feather = '../input/amex-agg-dataset-feather'\n    input_dir_pickle = '../input/amex-agg-data-pickle'\n    seed = 42\n    \nclass LGBCFG:\n    test_size = .2\n    boosting_rounds = 5000\n    params = {\n                    'objective': 'binary',\n                    'metric': \"binary_logloss\",\n                    'boosting': 'dart',\n                    'seed': CFG.seed,\n                    'max_bin': 250,\n                    'num_leaves': 300,\n                    'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_02_decay_power_099)],\n                    'feature_fraction': .5,\n                    'bagging_freq': 10,\n                    'bagging_fraction': .7,\n                    'n_jobs': -1,\n                    'lambda_l2': 2,\n                    'min_data_in_leaf': 40\n    }\n    \ndef import_df(train:bool = True):\n    if train:\n        df = pd.read_feather(os.path.join(CFG.input_dir_feather, 'train_agg_nonoise.ftr'))\n        df = df.dropna(axis=1, thresh=int(.8 * len(df)))\n                       \n    else:\n        df = pd.read_feather(os.path.join(CFG.input_dir_feather, 'test_agg_nonoise.ftr'))\n        df = df.loc[:,columns]\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:16:12.150304Z","iopub.execute_input":"2022-08-19T10:16:12.150825Z","iopub.status.idle":"2022-08-19T10:16:12.163417Z","shell.execute_reply.started":"2022-08-19T10:16:12.150781Z","shell.execute_reply":"2022-08-19T10:16:12.162352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:16:12.166661Z","iopub.execute_input":"2022-08-19T10:16:12.167383Z","iopub.status.idle":"2022-08-19T10:16:12.183888Z","shell.execute_reply.started":"2022-08-19T10:16:12.167349Z","shell.execute_reply":"2022-08-19T10:16:12.182696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_and_train(df:pd.DataFrame = None, use_gpu:bool = False, drop_first:bool = True, ram_reduc:bool = True):\n    sep_line = '-'*20\n    \n    print(f'[Info] Define categorical features\\n{sep_line}')\n    try:\n        print('Drop customer_ID and S_2')\n        features = df.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n    except KeyError:\n        features = df.columns.to_list()\n    cat_features = ['B_30','B_38','D_114','D_116','D_117','D_120','D_126','D_63','D_64','D_66','D_68']\n    \n    features_nocat = [c for c in features if c not in cat_features]\n    cat_features = [f'{cf}_last' for cf in cat_features]\n    \n    print(f'[Info] Calculate additional features\\n{sep_line}')\n    for col in df:\n        if 'last' in col and col.replace('last', 'first') in df:\n            #df[col + '_lag_sub'] = df[col] - df[col.replace('last', 'first')]\n            df[col + '_lag_div'] = df[col] / df[col.replace('last', 'first')]     \n    if drop_first:\n        print('[Info] Drop \"First\"-columns')\n        df = df.loc[:,df.columns.drop(list(df.filter(regex='first')))]\n        \n    df[\"c_PD_239\"]=df[\"D_39_last\"]/(df[\"P_2_last\"]*(-1)+0.0001)\n    df[\"c_PB_29\"]=df[\"P_2_last\"]*(-1)/(df[\"B_9_last\"]*(1)+0.0001)\n    df[\"c_PR_21\"]=df[\"P_2_last\"]*(-1)/(df[\"R_1_last\"]+0.0001)\n\n    df[\"c_BBBB\"]=(df[\"B_9_last\"]+0.001)/(df[\"B_23_last\"]+df[\"B_3_last\"]+0.0001)\n    df[\"c_BBBB1\"]=(df[\"B_33_last\"]*(-1))+(df[\"B_18_last\"]*(-1)+df[\"S_25_last\"]*(1)+0.0001)\n    df[\"c_BBBB2\"]=(df[\"B_19_last\"]+df[\"B_20_last\"]+df[\"B_4_last\"]+0.0001)\n\n    df[\"c_RRR0\"]=(df[\"R_3_last\"]+0.001)/(df[\"R_2_last\"]+df[\"R_4_last\"]+0.0001)\n    df[\"c_RRR1\"]=(df[\"D_62_last\"]+0.001)/(df[\"D_112_last\"]+df[\"R_27_last\"]+0.0001)\n\n    df[\"c_PD_348\"]=df[\"D_48_last\"]/(df[\"P_3_last\"]+0.0001)\n    df[\"c_PD_355\"]=df[\"D_55_last\"]/(df[\"P_3_last\"]+0.0001)\n\n    df[\"c_PD_439\"]=df[\"D_39_last\"]/(df[\"P_4_last\"]+0.0001)\n    df[\"c_PB_49\"]=df[\"B_9_last\"]/(df[\"P_4_last\"]+0.0001)\n    df[\"c_PR_41\"]=df[\"R_1_last\"]/(df[\"P_4_last\"]+0.0001)\n\n        \n    print(f'[Info] Total number of features: {len(df.columns)}')\n    gc.collect()\n    \n    print('[Info] Optimize memory usage')\n    df = reduce_mem_usage(df)\n    \n    print(f'[Info] Preprocess categorical features\\n{sep_line}')\n    cat_drop = []\n    for cf in cat_features:\n        if cf not in df.columns:\n            cat_drop.append(cf)\n    if len(cat_drop) > 0:\n        for cd in cat_drop:\n            cat_features.remove(cd)    \n                                                \n    print(f'[Info] Train-test-split\\n{sep_line}')\n    y = df.pop('TARGET')\n    cID = df.pop('customer_ID')\n    X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=LGBCFG.test_size)\n    \n    print(f'[Info] Delete unused dfs\\n{sep_line}')\n    del df\n    del cID\n    del y\n    gc.collect()\n                                                \n    print(f'[Info] Define amex eval-metric\\n{sep_line}')\n    def amex_metric(y_true, y_pred):\n        labels = np.transpose(np.array([y_true, y_pred]))\n        labels = labels[labels[:, 1].argsort()[::-1]]\n        weights = np.where(labels[:,0]==0, 20, 1)\n        cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n        top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n        gini = [0,0]\n        for i in [1,0]:\n            labels = np.transpose(np.array([y_true, y_pred]))\n            labels = labels[labels[:, i].argsort()[::-1]]\n            weight = np.where(labels[:,0]==0, 20, 1)\n            weight_random = np.cumsum(weight / np.sum(weight))\n            total_pos = np.sum(labels[:, 0] *  weight)\n            cum_pos_found = np.cumsum(labels[:, 0] * weight)\n            lorentz = cum_pos_found / total_pos\n            gini[i] = np.sum((lorentz - weight_random) * weight)\n        return 0.5 * (gini[1]/gini[0] + top_four)\n\n    def lgb_amex_metric(y_pred, y_true):\n        y_true = y_true.get_label()\n        return 'amex_metric', amex_metric(y_true, y_pred), True\n    \n    print(f'[Info] Build lgb datasets\\n{sep_line}')\n    lgb_train = lgb.Dataset(X_train, y_train, categorical_feature = cat_features)\n    lgb_valid = lgb.Dataset(X_test, y_test, categorical_feature = cat_features)\n    \n    print(f'[Info] Delete unused dfs\\n{sep_line}')\n    del X_train\n    del X_test\n    del y_train\n    del y_test\n    gc.collect()\n                                                \n    print(f'[Info] Define lgb-model and train it\\n{sep_line}') \n    if use_gpu:\n        print('[Info] Train on GPU')\n        LGBCFG.params['device'] = 'gpu'\n    else:\n        pass\n    if ram_reduc:\n        print(f'[Info] Limit RAM-usage\\n{sep_line}')\n        LGBCFG.params['histogram_pool_size '] = 1024\n    else:\n        pass\n    \n    m = lgb.train(\n            params = LGBCFG.params,\n            train_set = lgb_train,\n            num_boost_round = LGBCFG.boosting_rounds,\n            valid_sets = [lgb_train, lgb_valid],\n            verbose_eval = 100,\n            feval = lgb_amex_metric\n    )\n                                                \n    print('*'*20)\n    print('[FINISH Info] TRAINING FINISHED')\n    print(f'[Info] Returning trained model\\n{sep_line}')\n    return m","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:16:12.185646Z","iopub.execute_input":"2022-08-19T10:16:12.186394Z","iopub.status.idle":"2022-08-19T10:16:12.218803Z","shell.execute_reply.started":"2022-08-19T10:16:12.186356Z","shell.execute_reply":"2022-08-19T10:16:12.215944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_and_pred(df:pd.DataFrame = None, clf:object = None, drop_first:bool = True):\n    \n    sep_line = '-'*20\n    \n    print(f'[Info] Define categorical features\\n{sep_line}')\n    try:\n        print('Drop customer_ID and S_2')\n        features = df.drop(['customer_ID', 'S_2'], axis = 1).columns.to_list()\n    except KeyError:\n        features = df.columns.to_list()\n    cat_features = ['B_30','B_38','D_114','D_116','D_117','D_120','D_126','D_63','D_64','D_66','D_68']\n    \n    features_nocat = [c for c in features if c not in cat_features]\n    cat_features = [f'{cf}_last' for cf in cat_features]\n    \n    print(f'[Info] Calculate additional features\\n{sep_line}')\n    for col in df:\n        if 'last' in col and col.replace('last', 'first') in df:\n            #df[col + '_lag_sub'] = df[col] - df[col.replace('last', 'first')]\n            df[col + '_lag_div'] = df[col] / df[col.replace('last', 'first')]\n    if drop_first:\n        print('[Info] Drop \"First\"-columns')\n        df = df.loc[:,df.columns.drop(list(df.filter(regex='first')))]\n    \n    df[\"c_PD_239\"]=df[\"D_39_last\"]/(df[\"P_2_last\"]*(-1)+0.0001)\n    df[\"c_PB_29\"]=df[\"P_2_last\"]*(-1)/(df[\"B_9_last\"]*(1)+0.0001)\n    df[\"c_PR_21\"]=df[\"P_2_last\"]*(-1)/(df[\"R_1_last\"]+0.0001)\n\n    df[\"c_BBBB\"]=(df[\"B_9_last\"]+0.001)/(df[\"B_23_last\"]+df[\"B_3_last\"]+0.0001)\n    df[\"c_BBBB1\"]=(df[\"B_33_last\"]*(-1))+(df[\"B_18_last\"]*(-1)+df[\"S_25_last\"]*(1)+0.0001)\n    df[\"c_BBBB2\"]=(df[\"B_19_last\"]+df[\"B_20_last\"]+df[\"B_4_last\"]+0.0001)\n\n    df[\"c_RRR0\"]=(df[\"R_3_last\"]+0.001)/(df[\"R_2_last\"]+df[\"R_4_last\"]+0.0001)\n    df[\"c_RRR1\"]=(df[\"D_62_last\"]+0.001)/(df[\"D_112_last\"]+df[\"R_27_last\"]+0.0001)\n\n    df[\"c_PD_348\"]=df[\"D_48_last\"]/(df[\"P_3_last\"]+0.0001)\n    df[\"c_PD_355\"]=df[\"D_55_last\"]/(df[\"P_3_last\"]+0.0001)\n\n    df[\"c_PD_439\"]=df[\"D_39_last\"]/(df[\"P_4_last\"]+0.0001)\n    df[\"c_PB_49\"]=df[\"B_9_last\"]/(df[\"P_4_last\"]+0.0001)\n    df[\"c_PR_41\"]=df[\"R_1_last\"]/(df[\"P_4_last\"]+0.0001)\n\n    print(f'[Info] Total number of features: {len(df.columns)+1}')\n    gc.collect()\n    \n    print('[Info] Optimize memory usage')\n    df = reduce_mem_usage(df)\n    \n    print('[Info] Split dataframe into chunks')\n    df_list = np.array_split(df, 10)\n    del df\n    gc.collect()\n    \n    def chunk(df_list:list = None, i:int = None): return df_list[i]\n        \n    submission_dfs = []\n    for i in range(0,len(df_list)):\n        sdf = chunk(df_list,i)\n        customer_ID = sdf.pop('customer_ID')\n    \n        sep_line = '-'*200    \n        print(f'[Info] Predict testset {i+1}')\n        yhats = clf.predict(sdf)\n        s_sub = pd.DataFrame({'customer_ID':customer_ID, 'prediction':yhats})\n        submission_dfs.append(s_sub)\n        \n        del customer_ID\n        del yhats\n        del s_sub\n        del sdf\n    \n    submission = pd.concat(submission_dfs, axis=0)\n    \n    return submission    ","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:16:12.220213Z","iopub.execute_input":"2022-08-19T10:16:12.220732Z","iopub.status.idle":"2022-08-19T10:16:12.241885Z","shell.execute_reply.started":"2022-08-19T10:16:12.220699Z","shell.execute_reply":"2022-08-19T10:16:12.240676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG._TRAIN = True","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:16:12.243454Z","iopub.execute_input":"2022-08-19T10:16:12.244116Z","iopub.status.idle":"2022-08-19T10:16:12.255977Z","shell.execute_reply.started":"2022-08-19T10:16:12.244074Z","shell.execute_reply":"2022-08-19T10:16:12.254718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG._TRAIN:\n    df = import_df(train=True)\n    columns = list(df.columns)\n    columns.remove('TARGET')\n    clf = preprocess_and_train(df=df, use_gpu=False, drop_first=True, ram_reduc=True)\n    \n    del df\n    gc.collect()\n\n    clf.save_model('amex-lgb', num_iteration=clf.best_iteration)\n    print('[Info] Model saved')","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:16:12.258193Z","iopub.execute_input":"2022-08-19T10:16:12.258697Z","iopub.status.idle":"2022-08-19T10:18:52.742447Z","shell.execute_reply.started":"2022-08-19T10:16:12.258616Z","shell.execute_reply":"2022-08-19T10:18:52.741673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG._TRAIN = False","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:18:52.743748Z","iopub.execute_input":"2022-08-19T10:18:52.744396Z","iopub.status.idle":"2022-08-19T10:18:52.752287Z","shell.execute_reply.started":"2022-08-19T10:18:52.744358Z","shell.execute_reply":"2022-08-19T10:18:52.751131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG._TRAIN==False:\n    clf = lgb.Booster(model_file='./amex-lgb')\n    sub_df = import_df(train=False)\n    yhats = preprocess_and_pred(df=sub_df, clf=clf, drop_first=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:18:52.756453Z","iopub.execute_input":"2022-08-19T10:18:52.756838Z","iopub.status.idle":"2022-08-19T10:22:08.451662Z","shell.execute_reply.started":"2022-08-19T10:18:52.756809Z","shell.execute_reply":"2022-08-19T10:22:08.450548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhats.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T10:22:08.453716Z","iopub.execute_input":"2022-08-19T10:22:08.454103Z","iopub.status.idle":"2022-08-19T10:22:08.471273Z","shell.execute_reply.started":"2022-08-19T10:22:08.454066Z","shell.execute_reply":"2022-08-19T10:22:08.470285Z"},"trusted":true},"execution_count":null,"outputs":[]}]}