{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q tensorflow-recommenders\n!pip install -q fastparquet","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:43:04.820602Z","iopub.execute_input":"2023-01-31T14:43:04.821394Z","iopub.status.idle":"2023-01-31T14:44:42.978298Z","shell.execute_reply.started":"2023-01-31T14:43:04.821268Z","shell.execute_reply":"2023-01-31T14:44:42.974206Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.11.0 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow<2.7.0,>=2.6.0, but you have tensorflow 2.11.0 which is incompatible.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, but you have tensorflow-io-gcs-filesystem 0.30.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q tensorflow","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:44:42.983828Z","iopub.execute_input":"2023-01-31T14:44:42.984361Z","iopub.status.idle":"2023-01-31T14:44:55.263665Z","shell.execute_reply.started":"2023-01-31T14:44:42.984297Z","shell.execute_reply":"2023-01-31T14:44:55.262304Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Import packages\nimport gc\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport itertools\nfrom tqdm import tqdm\n\nfrom typing import Dict, Text\n\n\n# Import tensorflow package\nimport tensorflow as tf\nprint(f'Running tensorflow version {tf.__version__}')\n\n# Import tensorflow-recommenders package\nimport tensorflow_recommenders as tfrs","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-31T14:44:55.265668Z","iopub.execute_input":"2023-01-31T14:44:55.266087Z","iopub.status.idle":"2023-01-31T14:45:01.022578Z","shell.execute_reply.started":"2023-01-31T14:44:55.266049Z","shell.execute_reply":"2023-01-31T14:45:01.021317Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2023-01-31 14:44:55.306376: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-01-31 14:44:55.486101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2023-01-31 14:44:55.486177: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-01-31 14:44:57.131043: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2023-01-31 14:44:57.131393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2023-01-31 14:44:57.131418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"},{"name":"stdout","text":"Running tensorflow version 2.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"_BATCHSIZE = 16384\n_TEST_BATCHSIZE = _BATCHSIZE // 2\n_BASE_DIR = '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/'\n_TEST_DIR = '/kaggle/input/otto-chunk-data-inparquet-format/test_parquet/'\n_EPOCHS = 1","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:01.027943Z","iopub.execute_input":"2023-01-31T14:45:01.029546Z","iopub.status.idle":"2023-01-31T14:45:01.035952Z","shell.execute_reply.started":"2023-01-31T14:45:01.029490Z","shell.execute_reply":"2023-01-31T14:45:01.034683Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        elif 'datetime' not in col_type.name:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:01.037886Z","iopub.execute_input":"2023-01-31T14:45:01.038597Z","iopub.status.idle":"2023-01-31T14:45:01.058763Z","shell.execute_reply.started":"2023-01-31T14:45:01.038546Z","shell.execute_reply":"2023-01-31T14:45:01.057650Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"base_chunks = [#'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010000000_010100000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010100000_010200000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010200000_010300000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010300000_010400000.parquet',\n         #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010400000_010500000.parquet', \n         #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010500000_010600000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010600000_010700000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010700000_010800000.parquet',\n         #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010800000_010900000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/010900000_011000000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011000000_011100000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011100000_011200000.parquet',\n         #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011200000_011300000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011300000_011400000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011400000_011500000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011500000_011600000.parquet',\n         #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011600000_011700000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011700000_011800000.parquet', \n          #'/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011800000_011900000.parquet', \n          '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/011900000_012000000.parquet',\n         '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012000000_012100000.parquet', \n          '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012100000_012200000.parquet', \n          '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012200000_012300000.parquet', \n          '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012300000_012400000.parquet',\n         '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012400000_012500000.parquet', \n          '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012500000_012600000.parquet', \n          '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012600000_012700000.parquet', \n          '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012700000_012800000.parquet',\n         '/kaggle/input/otto-chunk-data-inparquet-format/train_parquet/012800000_012900000.parquet']\nadditional_chunks = glob(_TEST_DIR + '*.parquet')\nchunks = base_chunks + additional_chunks  ","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:01.060829Z","iopub.execute_input":"2023-01-31T14:45:01.061491Z","iopub.status.idle":"2023-01-31T14:45:01.082492Z","shell.execute_reply.started":"2023-01-31T14:45:01.061444Z","shell.execute_reply":"2023-01-31T14:45:01.081418Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_f = (pd\n      .read_parquet(glob(_BASE_DIR + '*.parquet'), engine='fastparquet')\n      .pipe(reduce_mem_usage)\n      .sort_values(by=['session'], ascending=True)\n      .reset_index(drop=True)\n     )\n\narticle_vocab = list(df_f['aid'].unique())\nsession_vocab = list(df_f['session'].unique())\ntype_vocab = ['clicks', 'carts', 'orders']\n\ndel df_f\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:01.083697Z","iopub.execute_input":"2023-01-31T14:45:01.084666Z","iopub.status.idle":"2023-01-31T14:45:01.093902Z","shell.execute_reply.started":"2023-01-31T14:45:01.084627Z","shell.execute_reply":"2023-01-31T14:45:01.092827Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"\"df_f = (pd\\n      .read_parquet(chunks, engine='fastparquet')\\n      .pipe(reduce_mem_usage)\\n      .sort_values(by=['session'], ascending=True)\\n      .reset_index(drop=True)\\n     )\\n\\narticle_vocab = list(df_f['aid'].unique())\\nsession_vocab = list(df_f['session'].unique())\\ntype_vocab = ['clicks', 'carts', 'orders']\\n\\ndel df_f\\ngc.collect()\""},"metadata":{}}]},{"cell_type":"code","source":"df = (pd.read_parquet(chunks, engine='fastparquet')\n          .pipe(reduce_mem_usage))\ndisplay(df.head(n=10))\ndisplay(df.info())","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:01.095487Z","iopub.execute_input":"2023-01-31T14:45:01.095841Z","iopub.status.idle":"2023-01-31T14:45:01.869546Z","shell.execute_reply.started":"2023-01-31T14:45:01.095809Z","shell.execute_reply":"2023-01-31T14:45:01.868637Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Memory usage of dataframe is 30.02 MB\nMemory usage after optimization is: 15.95 MB\nDecreased by 46.9%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    session      aid             ts    type\n0  10000000   938151  1660838216020  clicks\n1  10000000   938151  1660839335573  clicks\n2  10000001   921338  1660838216273   carts\n3  10000001   921338  1660838278053  clicks\n4  10000001   921338  1660838308474  clicks\n5  10000001   921338  1660838329660   carts\n6  10000002  1625942  1660838216523  clicks\n7  10000002  1196256  1661544246289  clicks\n8  10000002  1196256  1661544623231  clicks\n9  10000002  1196256  1661544715884  clicks","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>session</th>\n      <th>aid</th>\n      <th>ts</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000000</td>\n      <td>938151</td>\n      <td>1660838216020</td>\n      <td>clicks</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10000000</td>\n      <td>938151</td>\n      <td>1660839335573</td>\n      <td>clicks</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10000001</td>\n      <td>921338</td>\n      <td>1660838216273</td>\n      <td>carts</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10000001</td>\n      <td>921338</td>\n      <td>1660838278053</td>\n      <td>clicks</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10000001</td>\n      <td>921338</td>\n      <td>1660838308474</td>\n      <td>clicks</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10000001</td>\n      <td>921338</td>\n      <td>1660838329660</td>\n      <td>carts</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10000002</td>\n      <td>1625942</td>\n      <td>1660838216523</td>\n      <td>clicks</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10000002</td>\n      <td>1196256</td>\n      <td>1661544246289</td>\n      <td>clicks</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10000002</td>\n      <td>1196256</td>\n      <td>1661544623231</td>\n      <td>clicks</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10000002</td>\n      <td>1196256</td>\n      <td>1661544715884</td>\n      <td>clicks</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 983825 entries, 0 to 983824\nData columns (total 4 columns):\n #   Column   Non-Null Count   Dtype   \n---  ------   --------------   -----   \n 0   session  983825 non-null  int32   \n 1   aid      983825 non-null  int32   \n 2   ts       983825 non-null  int64   \n 3   type     983825 non-null  category\ndtypes: category(1), int32(2), int64(1)\nmemory usage: 16.0 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}]},{"cell_type":"code","source":"#article_vocab = list(df['aid'].unique())\n#session_vocab = list(df['session'].unique())\n#type_vocab = ['clicks', 'carts', 'orders']\n#df.info()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:01.870747Z","iopub.execute_input":"2023-01-31T14:45:01.871874Z","iopub.status.idle":"2023-01-31T14:45:01.948333Z","shell.execute_reply.started":"2023-01-31T14:45:01.871836Z","shell.execute_reply":"2023-01-31T14:45:01.947109Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 983825 entries, 0 to 983824\nData columns (total 4 columns):\n #   Column   Non-Null Count   Dtype   \n---  ------   --------------   -----   \n 0   session  983825 non-null  int32   \n 1   aid      983825 non-null  int32   \n 2   ts       983825 non-null  int64   \n 3   type     983825 non-null  category\ndtypes: category(1), int32(2), int64(1)\nmemory usage: 16.0 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"tensor = tf.data.Dataset.from_tensor_slices(dict(df))\ntensor = tf.data.Dataset.prefetch(tensor, buffer_size=tf.data.AUTOTUNE)\n\nfeatures = tensor.map(lambda x: {\n    \"session\": x[\"session\"],\n    \"type\": x[\"type\"],\n    \"aid\": x[\"aid\"]\n})\n\n\nunique_aids_df = pd.DataFrame(df['aid'].unique(), columns=['aid'])\ntargets = tf.data.Dataset.from_tensor_slices(dict(unique_aids_df))\ntargets = tf.data.Dataset.prefetch(targets, buffer_size=tf.data.AUTOTUNE)\n\ntargets = targets.map(lambda x: x[\"aid\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:01.952352Z","iopub.execute_input":"2023-01-31T14:45:01.952745Z","iopub.status.idle":"2023-01-31T14:45:02.206109Z","shell.execute_reply.started":"2023-01-31T14:45:01.952708Z","shell.execute_reply":"2023-01-31T14:45:02.204399Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2023-01-31 14:45:01.964613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2023-01-31 14:45:01.964669: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n2023-01-31 14:45:01.964699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5ce04aa06b7b): /proc/driver/nvidia/version does not exist\n2023-01-31 14:45:01.965288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"}]},{"cell_type":"code","source":"del df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:02.207723Z","iopub.execute_input":"2023-01-31T14:45:02.208128Z","iopub.status.idle":"2023-01-31T14:45:02.472879Z","shell.execute_reply.started":"2023-01-31T14:45:02.208090Z","shell.execute_reply":"2023-01-31T14:45:02.471378Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"75"},"metadata":{}}]},{"cell_type":"code","source":"tf.random.set_seed(42)\n\n#train = features.take(80_000)\n#test = features.skip(80_000).take(20_000)\n\ncached_train = features.cache().batch(_BATCHSIZE)\n#cached_test = test.cache().batch(_TEST_BATCHSIZE)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:02.474970Z","iopub.execute_input":"2023-01-31T14:45:02.475479Z","iopub.status.idle":"2023-01-31T14:45:02.497911Z","shell.execute_reply.started":"2023-01-31T14:45:02.475437Z","shell.execute_reply":"2023-01-31T14:45:02.496859Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class MultiObjectRetrieval(tfrs.Model):\n\n    def __init__(self, article_model, session_model, type_model):\n        \n        super().__init__()\n        \n        self.article_model: tf.keras.Model = article_model\n        self.session_model: tf.keras.Model = session_model\n        self.type_model: tf.keras.Model = type_model   \n        self.feat_model = tf.keras.Sequential([\n                    tf.keras.layers.Dense(16),\n                ])            \n            \n        self.task: tf.keras.layers.Layer = task\n\n\n    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n        \n        session_embeddings = self.session_model(features['session'])\n        article_embeddings = self.article_model(features['aid'])\n        type_embeddings = self.type_model(features['type'])\n        \n        return (\n            article_embeddings, \n                 self.feat_model(\n                tf.concat([session_embeddings, type_embeddings], axis=1)\n            )\n        )\n\n    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n        \n        article_embeddings, feature_embeddings = self(features)\n        \n        loss = self.task(feature_embeddings, article_embeddings)\n\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:02.499499Z","iopub.execute_input":"2023-01-31T14:45:02.499834Z","iopub.status.idle":"2023-01-31T14:45:02.514135Z","shell.execute_reply.started":"2023-01-31T14:45:02.499805Z","shell.execute_reply":"2023-01-31T14:45:02.512250Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"TPU = False\nif TPU:\n    print(\"Use TPU...\")\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelif tf.config.list_physical_devices('GPU'):\n    print(\"Use GPU devices...\")\n    strategy = (tf\n                .distribute\n                .MirroredStrategy(\n                    cross_device_ops = tf.distribute.HierarchicalCopyAllReduce() \n                                 )\n               )\nelif tf.config.list_physical_devices('CPU'):  \n    print(\"No GPUs/ TPUs available. Using default strategy...\")\n    strategy = tf.distribute.get_strategy()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:02.515942Z","iopub.execute_input":"2023-01-31T14:45:02.516530Z","iopub.status.idle":"2023-01-31T14:45:02.527584Z","shell.execute_reply.started":"2023-01-31T14:45:02.516481Z","shell.execute_reply":"2023-01-31T14:45:02.526229Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"No GPUs/ TPUs available. Using default strategy...\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nwith strategy.scope():\n    \n    article_model = tf.keras.Sequential(\n        [tf.keras.layers.IntegerLookup(vocabulary=article_vocab),      \n            tf.keras.layers.Embedding(len(article_vocab)+1, 16)]\n    )     \n\n    session_model = tf.keras.Sequential(\n        [tf.keras.layers.IntegerLookup(vocabulary=session_vocab),     \n            tf.keras.layers.Embedding(len(session_vocab)+1, 8)]\n    )   \n\n    type_model = tf.keras.Sequential(\n        [tf.keras.layers.StringLookup(vocabulary=type_vocab),     \n            tf.keras.layers.Embedding(len(type_vocab)+1, 8)]\n    )  \n\n    candidates = (targets.batch(128).map(article_model)\n    )\n\n    metrics = tfrs.metrics.FactorizedTopK(\n        candidates = candidates\n    )\n\n    task = tfrs.tasks.Retrieval(\n      metrics = metrics\n    )\n\n    \n    del tensor, train, test\n    gc.collect()\n    \n    model = MultiObjectRetrieval(article_model, session_model, type_model)\n    model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:02.529791Z","iopub.execute_input":"2023-01-31T14:45:02.530277Z","iopub.status.idle":"2023-01-31T14:45:12.661268Z","shell.execute_reply.started":"2023-01-31T14:45:02.530225Z","shell.execute_reply":"2023-01-31T14:45:12.660062Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"CPU times: user 10 s, sys: 150 ms, total: 10.2 s\nWall time: 10.1 s\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(cached_train, epochs=_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:45:12.662713Z","iopub.execute_input":"2023-01-31T14:45:12.663186Z","iopub.status.idle":"2023-01-31T14:59:11.445751Z","shell.execute_reply.started":"2023-01-31T14:45:12.663150Z","shell.execute_reply":"2023-01-31T14:59:11.444134Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"5/5 [==============================] - 835s 163s/step - factorized_top_k/top_1_categorical_accuracy: 7.5000e-05 - factorized_top_k/top_5_categorical_accuracy: 2.6250e-04 - factorized_top_k/top_10_categorical_accuracy: 3.5000e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0012 - factorized_top_k/top_100_categorical_accuracy: 0.0020 - loss: 152178.3594 - regularization_loss: 0.0000e+00 - total_loss: 152178.3594\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f7de7c9dd10>"},"metadata":{}}]},{"cell_type":"code","source":"#model.evaluate(cached_test, return_dict=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:59:11.447623Z","iopub.execute_input":"2023-01-31T14:59:11.447991Z","iopub.status.idle":"2023-01-31T14:59:11.452614Z","shell.execute_reply.started":"2023-01-31T14:59:11.447953Z","shell.execute_reply":"2023-01-31T14:59:11.451691Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"sample_pred = {\"session\": np.array([12899779]),\n      \"ts\": np.array([1661724000278]),\n      \"type\": np.array(['clicks']),\n      \"aid\": np.array([59625])\n      }\n\nsession_embeddings = model.session_model(sample_pred['session'])\ntype_embeddings = model.type_model(sample_pred['type'])\n\nindex = tfrs.layers.factorized_top_k.BruteForce(model.feat_model)\nindex.index_from_dataset(\n  tf.data.Dataset.zip((targets.batch(100), targets.batch(100).map(model.article_model)))\n)\n\n_, titles = index(tf.concat([session_embeddings, type_embeddings], axis=1))\nprint(f\"Recommendations for session {12899779}: {titles[:20]}\")","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:59:11.453993Z","iopub.execute_input":"2023-01-31T14:59:11.454391Z","iopub.status.idle":"2023-01-31T14:59:14.048908Z","shell.execute_reply.started":"2023-01-31T14:59:11.454349Z","shell.execute_reply":"2023-01-31T14:59:14.047634Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Recommendations for session 12899779: [[ 753525  979863 1796103  271231  199409 1255910 1731920 1242595  108125\n  1673641]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm\n\nindex = tfrs.layers.factorized_top_k.BruteForce(model.feat_model)\nindex.index_from_dataset(\n  tf.data.Dataset.zip((targets.batch(100), targets.batch(100).map(model.article_model)))\n)\ntest = pd.read_parquet(additional_chunks, engine='fastparquet')\ntest_session_AIDs = test.reset_index(drop=True).groupby('session')['aid'].apply(list)\ntest_session_types = test.reset_index(drop=True).groupby('session')['type'].apply(list)\ntypes = ['clicks', 'carts', 'orders']\ndel test\ngc.collect()\n\npreds_dict = {}\n\nsessiontypes_list = [str(session) + '_' + type for session in test_session_types.index for type in types]\nsessiontypes_list = [[int(st.split('_')[0]), st.split('_')[1]] for st in sessiontypes_list]\nsessions = [session[0] for session in sessiontypes_list]\nsessions_embeddings = model.session_model(np.array(sessions))\ntypes = [type[1] for type in sessiontypes_list]\ntypes_embeddings = model.type_model(np.array(types))\n\nfor i in tqdm(range(0,len(sessions_embeddings))):\n    _, titles = index(tf.concat([[sessions_embeddings[i]], [types_embeddings[i]]], axis=1))\n    preds_dict[str(sessions[i]) + '_' + types[i]] = titles[:20].numpy()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:59:14.050518Z","iopub.execute_input":"2023-01-31T14:59:14.050921Z","iopub.status.idle":"2023-01-31T15:06:53.366950Z","shell.execute_reply.started":"2023-01-31T14:59:14.050884Z","shell.execute_reply":"2023-01-31T15:06:53.364791Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"  1%|          | 51912/5015409 [06:15<9:58:50, 138.14it/s] \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3302865338.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msessions_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtypes_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mpreds_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 ):\n\u001b[0;32m-> 1132\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, queries, k)\u001b[0m\n\u001b[1;32m    584\u001b[0m       \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\u001b[0m in \u001b[0;36m_compute_score\u001b[0;34m(self, queries, candidates)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \"\"\"\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3713\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m         return gen_math_ops.mat_mul(\n\u001b[0;32m-> 3715\u001b[0;31m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   3716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6014\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   6015\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6016\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   6017\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6018\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"submission = pd.DataFrame({'session_type': preds_dict.keys(), 'labels': [list(i[0]) for i in list(preds_dict.values())]})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:06:56.710714Z","iopub.execute_input":"2023-01-31T15:06:56.711477Z","iopub.status.idle":"2023-01-31T15:06:57.295562Z","shell.execute_reply.started":"2023-01-31T15:06:56.711436Z","shell.execute_reply":"2023-01-31T15:06:57.294242Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"!mkdir -p saved_model\ntf.saved_model.save(index, '/kaggle/working/saved_model')","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:06:53.370418Z","iopub.status.idle":"2023-01-31T15:06:53.371053Z","shell.execute_reply.started":"2023-01-31T15:06:53.370742Z","shell.execute_reply":"2023-01-31T15:06:53.370773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loaded = tf.saved_model.load(path)\n#scores, titles = loaded([\"42\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-31T15:06:53.374357Z","iopub.status.idle":"2023-01-31T15:06:53.374843Z","shell.execute_reply.started":"2023-01-31T15:06:53.374621Z","shell.execute_reply":"2023-01-31T15:06:53.374642Z"},"trusted":true},"execution_count":null,"outputs":[]}]}